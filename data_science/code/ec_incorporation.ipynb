{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dotenv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-af3a65c813eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdotenv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dotenv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfind_dotenv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misdir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m### Load environmental variables from the project root directory ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dotenv'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from os.path import join, dirname, basename, exists, isdir\n",
    "\n",
    "### Load environmental variables from the project root directory ###\n",
    "# find .env automagically by walking up directories until it's found\n",
    "dotenv_path = find_dotenv()\n",
    "\n",
    "# load up the entries as environment variables\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "# now you can get the variables using their names\n",
    "\n",
    "# Check whether a network drive has been specified\n",
    "DATABASE = os.environ.get(\"NETWORK_URL\")\n",
    "if DATABASE == 'None':\n",
    "    pass\n",
    "else:\n",
    "    pass\n",
    "    #mount network drive here\n",
    "\n",
    "# set up directory paths\n",
    "CURRENT_DIR = os.getcwd()\n",
    "PROJ = dirname(dotenv_path) # project root directory\n",
    "\n",
    "DATA = join(PROJ, 'data') #data directory\n",
    "RAW_EXTERNAL = join(DATA, 'raw_external') # external data raw directory\n",
    "RAW_INTERNAL = join(DATA, 'raw_internal') # internal data raw directory\n",
    "INTERMEDIATE = join(DATA, 'intermediate') # intermediate data directory\n",
    "FINAL = join(DATA, 'final') # final data directory\n",
    "\n",
    "RESULTS = join(PROJ, 'results') # output directory\n",
    "FIGURES = join(RESULTS, 'figures') # figure output directory\n",
    "PICTURES = join(RESULTS, 'pictures') # picture output directory\n",
    "\n",
    "\n",
    "# make folders specific for certain data\n",
    "folder_name = ''\n",
    "if folder_name != '':\n",
    "    #make folders if they don't exist\n",
    "    if not exists(join(RAW_EXTERNAL, folder_name)):\n",
    "        os.makedirs(join(RAW_EXTERNAL, folder_name))\n",
    "\n",
    "    if not exists(join(INTERMEDIATE, folder_name)):\n",
    "        os.makedirs(join(INTERMEDIATE, folder_name))\n",
    "\n",
    "    if not exists(join(FINAL, folder_name)):\n",
    "        os.makedirs(join(FINAL, folder_name))\n",
    "\n",
    "\n",
    "print('Standard variables loaded, you are good to go!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(null);\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(null);\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cobra\n",
    "import os\n",
    "import pandas as pd\n",
    "import cameo\n",
    "import wget\n",
    "import ssl\n",
    "\n",
    "\n",
    "#E. coli model:\n",
    "#eColi_model = cameo.load_model(\"iML1515\")\n",
    "\n",
    "\n",
    "#E. coli model:\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "wget.download(\"https://raw.githubusercontent.com/BenjaSanchez/notebooks/master/e_coli_simulations/eciML1515.xml\")\n",
    "eColi_Model = cobra.io.read_sbml_model(\"eciML1515.xml\")\n",
    "os.remove(\"eciML1515.xml\")\n",
    "\n",
    "\n",
    "\n",
    "#proteomics data:\n",
    "proteomics_dataset = \"~/Documents/masters/thesis/thesis/data/raw_internal/proteomics/protein_values.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from cobra.medium.boundary_types import find_external_compartment\n",
    "from cobra.io.dict import reaction_to_dict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def apply_medium(model, is_ec_model, medium):\n",
    "    operations = []\n",
    "    warnings = []\n",
    "    errors = []\n",
    "\n",
    "    # Convert the list of dicts to a set of namedtuples to avoid duplicates, as\n",
    "    # looking up metabolites in the model is a somewhat expensive operation.\n",
    "    Compound = namedtuple(\"Compound\", [\"id\", \"namespace\"])\n",
    "    medium = set(Compound(id=c[\"identifier\"], namespace=c[\"namespace\"]) for c in medium)\n",
    "\n",
    "    # Add trace metals\n",
    "    medium.update(\n",
    "        [\n",
    "            Compound(id=\"CHEBI:25517\", namespace=\"chebi\"),\n",
    "            Compound(id=\"CHEBI:25368\", namespace=\"chebi\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        extracellular = find_external_compartment(model)\n",
    "    except RuntimeError as error:\n",
    "        # cobrapy throws RuntimeError if it for any reason is unable to find an\n",
    "        # external compartment. See:\n",
    "        # https://github.com/opencobra/cobrapy/blob/95d920d135fa824e6087f1fcbc88d50882da4dab/cobra/medium/boundary_types.py#L26\n",
    "        message = (\n",
    "            f\"Cannot find an external compartment in model {model.id}: {str(error)}\"\n",
    "        )\n",
    "        errors.append(message)\n",
    "        # Cannot continue without knowing the external compartment, so\n",
    "        # immediately return the error.\n",
    "        return operations, warnings, errors\n",
    "\n",
    "    # Create a map of exchange reactions and corresponding fluxes to apply to\n",
    "    # the medium.\n",
    "    medium_mapping = {}\n",
    "    for compound in medium:\n",
    "        print(compound)\n",
    "        try:\n",
    "            extracellular_metabolite = find_metabolite(\n",
    "                model, compound.id, compound.namespace, extracellular\n",
    "            )\n",
    "        except MetaboliteNotFound:\n",
    "            warning = (\n",
    "                f\"Cannot add medium compound '{compound.id}' - metabolite not found in \"\n",
    "                f\"extracellular compartment '{extracellular}'\"\n",
    "            )\n",
    "            warnings.append(warning)\n",
    "        else:\n",
    "            exchange_reactions = extracellular_metabolite.reactions.intersection(\n",
    "                model.exchanges\n",
    "            )\n",
    "            if is_ec_model and len(exchange_reactions) == 2:\n",
    "                exchange_reactions = get_ec_exchange_reaction(exchange_reactions, True)\n",
    "            if len(exchange_reactions) != 1:\n",
    "                errors.append(\n",
    "                    f\"Medium compound metabolite '{extracellular_metabolite.id}' has \"\n",
    "                    f\"{len(exchange_reactions)} exchange reactions in the model; \"\n",
    "                    f\"expected 1\"\n",
    "                )\n",
    "                continue\n",
    "            exchange_reaction = next(iter(exchange_reactions))\n",
    "\n",
    "            # If someone already figured out the uptake rate for the compound, it's\n",
    "            # likely more accurate than our assumptions, so keep it\n",
    "            if exchange_reaction.id in model.medium:\n",
    "                medium_mapping[exchange_reaction.id] = model.medium[\n",
    "                    exchange_reaction.id\n",
    "                ]\n",
    "                continue\n",
    "\n",
    "            if not extracellular_metabolite.formula:\n",
    "                warning = (\n",
    "                    f\"No formula for metabolite '{extracellular_metabolite.id}', cannot\"\n",
    "                    f\" check if it is a carbon source\"\n",
    "                )\n",
    "                warnings.append(warning)\n",
    "                # If we don't know, it's most likely that the metabolite does not have a\n",
    "                # higher uptake rate than a carbon source, so set the bound still to 10\n",
    "                medium_mapping[exchange_reaction.id] = 10\n",
    "            elif \"C\" in extracellular_metabolite.elements:\n",
    "                # Limit the uptake rate for carbon sources to 10\n",
    "                medium_mapping[exchange_reaction.id] = 10\n",
    "            else:\n",
    "                medium_mapping[exchange_reaction.id] = 1000\n",
    "\n",
    "    # Apply the medium to the model, letting cobrapy deal with figuring out the correct\n",
    "    # bounds to change\n",
    "    model.medium = medium_mapping\n",
    "\n",
    "    # Add all exchange reactions to operations, to make sure any changed bounds is\n",
    "    # properly updated\n",
    "    for reaction in model.exchanges:\n",
    "        operations.append(\n",
    "            {\n",
    "                \"operation\": \"modify\",\n",
    "                \"type\": \"reaction\",\n",
    "                \"id\": reaction.id,\n",
    "                \"data\": reaction_to_dict(reaction),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return operations, warnings, errors\n",
    "\n",
    "\n",
    "def apply_measurements(\n",
    "    model,\n",
    "    biomass_reaction,\n",
    "    is_ec_model,\n",
    "    fluxomics,\n",
    "    metabolomics,\n",
    "    proteomics,\n",
    "    uptake_secretion_rates,\n",
    "    molar_yields,\n",
    "    growth_rate,\n",
    "):\n",
    "    operations = []\n",
    "    warnings = []\n",
    "    errors = []\n",
    "\n",
    "    def bounds(measurement, uncertainty):\n",
    "        \"\"\"Return resolved bounds based on measurement and uncertainty\"\"\"\n",
    "        if uncertainty:\n",
    "            return (measurement - uncertainty, measurement + uncertainty)\n",
    "        else:\n",
    "            return (measurement, measurement)\n",
    "\n",
    "    # If an enzyme constrained model with proteomics was supplied, flexibilize the\n",
    "    # proteomics data and redefine the growth rate based on simulations.\n",
    "    if growth_rate and proteomics and is_ec_model:\n",
    "        growth_rate, proteomics, prot_warnings = flexibilize_proteomics(\n",
    "            model, biomass_reaction, growth_rate, proteomics\n",
    "        )\n",
    "        for warning in prot_warnings:\n",
    "            warnings.append(warning)\n",
    "\n",
    "    # Constrain the model with the observed growth rate\n",
    "    if growth_rate:\n",
    "        reaction = model.reactions.get_by_id(biomass_reaction)\n",
    "        reaction.bounds = bounds(growth_rate[\"measurement\"], growth_rate[\"uncertainty\"])\n",
    "        operations.append(\n",
    "            {\n",
    "                \"operation\": \"modify\",\n",
    "                \"type\": \"reaction\",\n",
    "                \"id\": reaction.id,\n",
    "                \"data\": reaction_to_dict(reaction),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    for measure in fluxomics:\n",
    "        try:\n",
    "            reaction = model.reactions.get_by_id(measure[\"identifier\"])\n",
    "        except KeyError:\n",
    "            errors.append(\n",
    "                f\"Cannot find reaction '{measure['identifier']}' in the model\"\n",
    "            )\n",
    "        else:\n",
    "            reaction.bounds = bounds(measure[\"measurement\"], measure[\"uncertainty\"])\n",
    "            operations.append(\n",
    "                {\n",
    "                    \"operation\": \"modify\",\n",
    "                    \"type\": \"reaction\",\n",
    "                    \"id\": reaction.id,\n",
    "                    \"data\": reaction_to_dict(reaction),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    for metabolite in metabolomics:\n",
    "        warning = (\n",
    "            f\"Cannot apply metabolomics measure for '{metabolite['identifier']}'; \"\n",
    "            f\"feature has not yet been implemented\"\n",
    "        )\n",
    "        warnings.append(warning)\n",
    "\n",
    "    for measure in proteomics:\n",
    "        if is_ec_model:\n",
    "            try:\n",
    "                reaction = model.reactions.get_by_id(\n",
    "                    f\"prot_{measure['identifier']}_exchange\"\n",
    "                )\n",
    "            except KeyError:\n",
    "                warning = f\"Cannot find protein '{measure['identifier']}' in the model\"\n",
    "                warnings.append(warning)\n",
    "            else:\n",
    "                # measurement only modifies the upper bound (enzymes can be unsaturated)\n",
    "                lb, ub = bounds(measure[\"measurement\"], measure[\"uncertainty\"])\n",
    "                reaction.bounds = 0, ub\n",
    "                operations.append(\n",
    "                    {\n",
    "                        \"operation\": \"modify\",\n",
    "                        \"type\": \"reaction\",\n",
    "                        \"id\": reaction.id,\n",
    "                        \"data\": reaction_to_dict(reaction),\n",
    "                    }\n",
    "                )\n",
    "        else:\n",
    "            warning = (\n",
    "                f\"Cannot apply proteomics measurements for \"\n",
    "                f\"non enzyme-constrained model {model.id}\"\n",
    "            )\n",
    "            warnings.append(warning)\n",
    "            break\n",
    "\n",
    "    for rate in uptake_secretion_rates:\n",
    "        try:\n",
    "            metabolite = find_metabolite(\n",
    "                model, rate[\"identifier\"], rate[\"namespace\"], \"e\"\n",
    "            )\n",
    "        except MetaboliteNotFound as error:\n",
    "            errors.append(str(error))\n",
    "        else:\n",
    "            exchange_reactions = metabolite.reactions.intersection(model.exchanges)\n",
    "            if is_ec_model and len(exchange_reactions) == 2:\n",
    "                exchange_reactions = get_ec_exchange_reaction(\n",
    "                    exchange_reactions, rate[\"measurement\"] < 0\n",
    "                )\n",
    "            if len(exchange_reactions) != 1:\n",
    "                errors.append(\n",
    "                    f\"Measured metabolite '{metabolite['identifier']}' has \"\n",
    "                    f\"{len(exchange_reactions)} exchange reactions in the model; \"\n",
    "                    f\"expected 1\"\n",
    "                )\n",
    "                continue\n",
    "            exchange_reaction = next(iter(exchange_reactions))\n",
    "            lower_bound, upper_bound = bounds(rate[\"measurement\"], rate[\"uncertainty\"])\n",
    "\n",
    "            # data is adjusted assuming a forward exchange reaction, i.e. x -->\n",
    "            # (sign = -1), so if we instead actually have --> x, then multiply with -1\n",
    "            direction = exchange_reaction.metabolites[metabolite]\n",
    "            if direction > 0:\n",
    "                lower_bound, upper_bound = -1 * lower_bound, -1 * upper_bound\n",
    "            exchange_reaction.bounds = lower_bound, upper_bound\n",
    "            operations.append(\n",
    "                {\n",
    "                    \"operation\": \"modify\",\n",
    "                    \"type\": \"reaction\",\n",
    "                    \"id\": exchange_reaction.id,\n",
    "                    \"data\": reaction_to_dict(exchange_reaction),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    for molar_yield in molar_yields:\n",
    "        warning = (\n",
    "            f\"Cannot apply molar yield measurement for '\"\n",
    "            f\"{molar_yield['product_identifier']}/{molar_yield['substrate_identifier']}\"\n",
    "            f\"'; feature has not yet been implemented\"\n",
    "        )\n",
    "        warnings.append(warning)\n",
    "    return operations, warnings, errors\n",
    "\n",
    "\n",
    "def flexibilize_proteomics(model, biomass_reaction, growth_rate, proteomics):\n",
    "    # reset growth rate in model:\n",
    "    model.reactions.get_by_id(biomass_reaction).bounds = (0, 1000)\n",
    "\n",
    "    # build a table with protein ids, met ids in model and values to constrain with:\n",
    "    prot_df = pd.DataFrame()\n",
    "    for protein in proteomics:\n",
    "        protein_id = protein[\"identifier\"]\n",
    "        lb, ub = bounds(protein[\"measurement\"], protein[\"uncertainty\"])\n",
    "        \n",
    "        for met in model.metabolites.query(lambda m: protein_id in m.id):\n",
    "            new_row = pd.DataFrame(\n",
    "                data={\"met_id\": met.id, \"value\": ub}, index=[protein_id]\n",
    "            )\n",
    "            prot_df = prot_df.append(new_row)\n",
    "\n",
    "    # constrain the model with all proteins and optimize:\n",
    "    \n",
    "    limit_proteins(model, prot_df[\"value\"])\n",
    "    solution = model.optimize()\n",
    "    new_growth_rate = solution.objective_value\n",
    "\n",
    "    # while the model cannot grow to the desired level, remove the protein with\n",
    "    # the highest shadow price:\n",
    "    minimal_growth, ub = bounds(growth_rate[\"measurement\"], growth_rate[\"uncertainty\"])\n",
    "    prots_to_remove = []\n",
    "    warnings = []\n",
    "    while new_growth_rate < minimal_growth and not prot_df.empty:\n",
    "        # get most influential protein in model:\n",
    "        top_protein = top_shadow_prices(solution, list(prot_df[\"met_id\"]))\n",
    "        value = top_protein[top_protein.index[0]]\n",
    "        top_protein = top_protein.index[0]\n",
    "        top_protein = prot_df.index[prot_df[\"met_id\"] == top_protein][0]\n",
    "        print(\"working: \" + top_protein + \" (sp=\" + str(value) + \") - mu = \" + str(new_growth_rate))\n",
    "\n",
    "        # update data: append protein to list, remove from current dataframe and\n",
    "        # increase the corresponding upper bound to +1000:\n",
    "        prots_to_remove.append(top_protein)\n",
    "        prot_df = prot_df.drop(labels=top_protein)\n",
    "        limit_proteins(model, pd.Series(data=[1000], index=[top_protein]))\n",
    "        warning = (\n",
    "            f\"Removed protein '{top_protein}' from the proteomics data for feasible \"\n",
    "            f\"simulations\"\n",
    "        )\n",
    "        warnings.append(warning)\n",
    "\n",
    "        # re-compute solution:\n",
    "        solution = model.optimize()\n",
    "        if solution.objective_value == new_growth_rate:  # the algorithm is stuck\n",
    "            break\n",
    "        new_growth_rate = solution.objective_value\n",
    "\n",
    "    # update growth rate if optimization was not successful:\n",
    "    if new_growth_rate < minimal_growth:\n",
    "        if growth_rate[\"uncertainty\"]:\n",
    "            growth_rate[\"measurement\"] = new_growth_rate + growth_rate[\"uncertainty\"]\n",
    "        else:\n",
    "            growth_rate[\"measurement\"] = new_growth_rate\n",
    "\n",
    "    # update proteomics by removing flexibilized proteins:\n",
    "    for protein in prots_to_remove:\n",
    "        index = next(\n",
    "            (\n",
    "                index\n",
    "                for (index, dic) in enumerate(proteomics)\n",
    "                if dic[\"identifier\"] == protein\n",
    "            ),\n",
    "            None,\n",
    "        )\n",
    "        del proteomics[index]\n",
    "\n",
    "    return growth_rate, proteomics, warnings\n",
    "\n",
    "\n",
    "def limit_proteins(model, measurements):\n",
    "    for protein_id, measure in measurements.items():\n",
    "        try:\n",
    "            rxn = model.reactions.get_by_id(f\"prot_{protein_id}_exchange\")\n",
    "        except KeyError:\n",
    "            pass\n",
    "        else:\n",
    "            # update only upper_bound (as enzymes can be unsaturated):\n",
    "            rxn.bounds = (0, measure)\n",
    "    return\n",
    "\n",
    "\n",
    "def top_shadow_prices(solution, met_ids, top=1):\n",
    "    shadow_pr = solution.shadow_prices\n",
    "    shadow_pr = shadow_pr.loc[shadow_pr.index.isin(met_ids)]\n",
    "    return shadow_pr.sort_values()[:top]\n",
    "\n",
    "\n",
    "def bounds(measurement, uncertainty):\n",
    "    if uncertainty:\n",
    "        return measurement - uncertainty, measurement + uncertainty\n",
    "    else:\n",
    "        return measurement, measurement\n",
    "\n",
    "\n",
    "def find_metabolite(model, id, namespace, compartment):\n",
    "    def query_fun(metabolite):\n",
    "        if metabolite.compartment != compartment:\n",
    "            return False\n",
    "\n",
    "        result = _query_item(metabolite, id, namespace)\n",
    "        if result:\n",
    "            return result\n",
    "\n",
    "        # If the original query fails, retry with the compartment id appended\n",
    "        # to the identifier (a regular convenation with BiGG metabolites, but\n",
    "        # may also be the case in other namespaces).\n",
    "        return _query_item(metabolite, f\"{id}_{compartment}\", namespace)\n",
    "\n",
    "    metabolites = model.metabolites.query(query_fun)\n",
    "    if len(metabolites) == 0:\n",
    "        raise MetaboliteNotFound(\n",
    "            f\"Could not find metabolite {id} or {id}_{compartment} in \"\n",
    "            f\"namespace {namespace} and compartment {compartment} for model \"\n",
    "            f\"{model.id}\"\n",
    "        )\n",
    "    elif len(metabolites) > 1:\n",
    "        raise IndexError(f\"Expected single metabolite, found {metabolites}\")\n",
    "    else:\n",
    "        return metabolites[0]\n",
    "\n",
    "def _query_item(item, query_id, query_namespace):\n",
    "    # Try the default identifiers (without confirming the namespace)\n",
    "    if query_id.lower() == item.id.lower():\n",
    "        return True\n",
    "\n",
    "    # Otherwise, try to find a case insensitive match for the namespace key\n",
    "    for namespace in item.annotation:\n",
    "        if query_namespace.lower() == namespace.lower():\n",
    "            annotation = item.annotation[namespace]\n",
    "            # Compare the identifier case insensitively as well\n",
    "            # Annotations may contain a single id or a list of ids\n",
    "            if isinstance(annotation, list):\n",
    "                if query_id.lower() in [i.lower() for i in annotation]:\n",
    "                    return True\n",
    "            else:\n",
    "                if query_id.lower() == annotation.lower():\n",
    "                    return True\n",
    "    return False\n",
    "\n",
    "def compute_measurements(proteomics, ecModel):\n",
    "    measurements = pd.DataFrame()\n",
    "    for protein in proteomics:\n",
    "        protein_id = protein[\"identifier\"]\n",
    "        lb, ub = bounds(protein[\"measurement\"], protein[\"uncertainty\"])\n",
    "        for met in ecModel.metabolites:\n",
    "            if protein_id in met.id:\n",
    "                new_row = pd.DataFrame(data={\"met_id\": met.id, \"value\": ub}, index=[protein_id])\n",
    "                measurements = measurements.append(new_row)\n",
    "    return measurements\n",
    "\n",
    "def get_ec_exchange_reaction(exchange_reactions, consumption):\n",
    "    ec_exchange_reaction = []\n",
    "    for reaction in exchange_reactions:\n",
    "        if (reaction.products and consumption) or (reaction.reactants and not consumption):\n",
    "            ec_exchange_reaction.append(reaction)\n",
    "    return ec_exchange_reaction\n",
    "\n",
    "class MetaboliteNotFound(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_proteomics():\n",
    "    data = pd.read_csv(proteomics_dataset)  # yeast\n",
    "\n",
    "    # cols_measurements \n",
    "    cols_measurements = data.columns[data.columns.get_loc(\"Glucose\"):data.columns.get_loc(\"Fructose\")]\n",
    "\n",
    "    # cols uncertainties\n",
    "    cols_uncertainties = data.columns[data.columns.get_loc(\"Glucose.1\"):data.columns.get_loc(\"Fructose.1\")]\n",
    "\n",
    "    # E. coli\n",
    "    proteomics_all = dict()\n",
    "    for i in range(0,len(cols_measurements)):\n",
    "        measurement = cols_measurements[i]\n",
    "        proteomics = []\n",
    "        for j in range(0,data.shape[0]):\n",
    "            protein = {\"identifier\":data[\"Uniprot Accession\"][j], \\\n",
    "            \"measurement\":data[cols_measurements[i]][j], \\\n",
    "            \"uncertainty\":data[cols_uncertainties[i]][j]}\n",
    "            proteomics.append(protein)\n",
    "        proteomics_all[cols_measurements[i]] = proteomics\n",
    "    return(proteomics_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "proteomics_data_dict = reset_proteomics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#solution = ecModel.optimize()\n",
    "ecModel.reactions.CPGNR1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_proteomics = [\n",
    "    {\"identifier\": \"P0A8V2\", \"measurement\": 5.03e-6, \"uncertainty\": 0},  # not in model\n",
    "    {\"identifier\": \"P0AFG8\", \"measurement\": 8.2e-3, \"uncertainty\": 8.2e-6},  # will stay\n",
    "    {\"identifier\": \"P15254\", \"measurement\": 6.54e-8, \"uncertainty\": 0},  # to remove\n",
    "    {\"identifier\": \"P0A6C5\", \"measurement\": 5.93e-8, \"uncertainty\": 0},  # to remove\n",
    "]\n",
    "measurements = compute_measurements(proteomics_data_dict[\"Glucose\"], ecModel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prot_P0AFG8\n",
      "{'measurement': 0.1, 'uncertainty': 0.01}\n",
      "[{'identifier': 'P0A8V2', 'measurement': 5.03e-06, 'uncertainty': 0}, {'identifier': 'P0AFG8', 'measurement': 0.0082, 'uncertainty': 8.2e-06}]\n",
      "<Solution 0.877 at 0x12f23b0b8>\n"
     ]
    }
   ],
   "source": [
    "# check if incorporation seems to work\n",
    "new_growth_rate, new_proteomics, warnings = flexibilize_proteomics(ecModel, \"BIOMASS_Ec_iML1515_core_75p37M\", {\"measurement\":0.1, \"uncertainty\":0.01}, fake_proteomics)\n",
    "print(new_growth_rate)\n",
    "print(new_proteomics)\n",
    "solution = ecModel.optimize()\n",
    "print(solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run on real data and growth rates\n",
    "data = pd.read_csv(proteomics_dataset)\n",
    "cols_measurements = data.columns[data.columns.get_loc(\"Glucose\"):data.columns.get_loc(\"Fructose\")]\n",
    "\n",
    "growth_rates = pd.read_csv(\"/Users/jonas/Documents/masters/thesis/thesis/data/raw_internal/proteomics/growth_conditions.csv\")\n",
    "growth_rates = growth_rates.drop(growth_rates.columns.difference(['Growth condition','Growth rate (h-1)', 'Stdev']), 1)\n",
    "growth_rates = growth_rates.drop([0,1], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 of 21\n",
      "Model 2 of 21\n",
      "working: P60782 (sp=-2.9103830456733704e-11) - mu = 0.8769973133963621\n",
      "working: P0A867 (sp=-2.842170943040401e-14) - mu = 0.8769973133963647\n",
      "Model 3 of 21\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Something is wrong with the provided bounds 0.000000 and nan in variable 0 <= prot_P0A9P9_exchange <= nan",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-2492ba3388b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     {\"measurement\":float(list(growth_rates['Growth rate (h-1)'].loc[growth_rates['Growth condition'] == i])[0]),\\\n\u001b[1;32m     11\u001b[0m     \"uncertainty\":float(list(growth_rates['Stdev'].loc[growth_rates['Growth condition'] == i])[0])}, \\\n\u001b[0;32m---> 12\u001b[0;31m     proteomics_data_dict[i])\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0msolutions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mecModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-60-ad74e5fa2554>\u001b[0m in \u001b[0;36mflexibilize_proteomics\u001b[0;34m(model, biomass_reaction, growth_rate, proteomics)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;31m# constrain the model with all proteins and optimize:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0mlimit_proteins\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprot_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m     \u001b[0msolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0mnew_growth_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-60-ad74e5fa2554>\u001b[0m in \u001b[0;36mlimit_proteins\u001b[0;34m(model, measurements)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0;31m# update only upper_bound (as enzymes can be unsaturated):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m             \u001b[0mrxn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeasure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/3.7/site-packages/cobra/util/context.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, new_value)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/3.7/site-packages/cobra/core/reaction.py\u001b[0m in \u001b[0;36mbounds\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lower_bound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_upper_bound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_variable_bounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/3.7/site-packages/cobra/core/reaction.py\u001b[0m in \u001b[0;36mupdate_variable_bounds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    214\u001b[0m             self.forward_variable.set_bounds(\n\u001b[1;32m    215\u001b[0m                 \u001b[0mlb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                 \u001b[0mub\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_upper_bound\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_upper_bound\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             )\n\u001b[1;32m    218\u001b[0m             self.reverse_variable.set_bounds(\n",
      "\u001b[0;32m/Library/Python/3.7/site-packages/optlang/glpk_interface.py\u001b[0m in \u001b[0;36mset_bounds\u001b[0;34m(self, lb, ub)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_bounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_glpk_set_col_bounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/3.7/site-packages/optlang/glpk_interface.py\u001b[0m in \u001b[0;36m_glpk_set_col_bounds\u001b[0;34m(self, variable)\u001b[0m\n\u001b[1;32m    800\u001b[0m             raise Exception(\n\u001b[1;32m    801\u001b[0m                 \u001b[0;34m\"Something is wrong with the provided bounds %f and %f in variable %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m                 (variable.lb, variable.ub, variable))\n\u001b[0m\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_glpk_is_mip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Something is wrong with the provided bounds 0.000000 and nan in variable 0 <= prot_P0A9P9_exchange <= nan"
     ]
    }
   ],
   "source": [
    "# run all  \n",
    "solutions = dict()\n",
    "errors = []\n",
    "counter = 0\n",
    "for i in cols_measurements:\n",
    "    counter += 1\n",
    "    print(\"Model {} of {}\".format(counter, len(cols_measurements)))\n",
    "\n",
    "    new_growth_rate, new_proteomics, warnings = flexibilize_proteomics(ecModel, \"BIOMASS_Ec_iML1515_core_75p37M\", \\\n",
    "    {\"measurement\":float(list(growth_rates['Growth rate (h-1)'].loc[growth_rates['Growth condition'] == i])[0]),\\\n",
    "    \"uncertainty\":float(list(growth_rates['Stdev'].loc[growth_rates['Growth condition'] == i])[0])}, \\\n",
    "    proteomics_data_dict[i])\n",
    "    solutions[i] = ecModel.optimize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Reaction' object has no attribute 'gene'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-fbb9ca9c65b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meColi_Model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEX_acgam_e\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgene\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Reaction' object has no attribute 'gene'"
     ]
    }
   ],
   "source": [
    "eColi_Model.reactions.EX_acgam_e.gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
